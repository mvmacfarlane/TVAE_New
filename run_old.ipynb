{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mvmacfarlane/miniconda3/envs/CVAE_env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from trainy import train\n",
    "import toy\n",
    "import numpy as np\n",
    "import datetime\n",
    "from model import NN_Solver\n",
    "from toy import Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create config\n",
    "\n",
    "config = Namespace(\n",
    "\n",
    "    #Running Settings\n",
    "    output_path = \"\",\n",
    "    device = \"cuda\",\n",
    "    model_path = None,\n",
    "\n",
    "    #Training\n",
    "    batch_size = 512,\n",
    "    epoch_size = 93440,\n",
    "    nb_epochs = 80 ,\n",
    "    lr = 1e-4,\n",
    "    lr_imp = 1e-5,\n",
    "\n",
    "    gaussian_eval_num = 93440,\n",
    "\n",
    "    #Loss\n",
    "    KLD_weight = 1e-3, #0.001\n",
    "    Centering_weight = 1e-2, #0.001\n",
    "\n",
    "\n",
    "    weighting = True,\n",
    "    weighting_temp = 1,\n",
    "    sample_model = False,\n",
    "    testing_decoding_greedy = True,\n",
    "\n",
    "    #Problem\n",
    "    problem = \"smooth_1\",  #smooth_1 chess\n",
    " \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the output path6\n",
    "#The generaton of models needs switched\n",
    "#exp_name = \"baseline_smooth_with_weighting_exp:temp:5_model_sampling\"\n",
    "exp_name = \"debug_contexts\"\n",
    "#exp_name = \"baseline_weighting_exp:1_uniform_centering_loss_Centering_Weight:1e-1_pure_reward\"\n",
    "\n",
    "config.exp_name = exp_name\n",
    "run_id = np.random.randint(10000, 99999)\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "if config.output_path == \"\":\n",
    "    config.output_path = os.getcwd()\n",
    "    config.output_path_fixed = config.output_path\n",
    "    config.output_path = os.path.join(config.output_path,\"experiment_info\", config.exp_name + \":_\" + str(now.day) + \".\" + str(now.month) +\".\" + str(now.year) + \"_\" + str(run_id))\n",
    "\n",
    "    os.makedirs(os.path.join(config.output_path, \"models\"))\n",
    "    os.makedirs(os.path.join(config.output_path, \"latent_images\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-07 11:50:38.510737: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-07 11:50:38.637254: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-07 11:50:39.155267: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-07 11:50:39.155320: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-07 11:50:39.155326: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1\n",
      "Epoch:2\n",
      "Epoch:3\n",
      "Epoch:4\n",
      "Epoch:5\n",
      "Epoch:6\n",
      "Epoch:7\n",
      "Epoch:8\n",
      "Epoch:9\n",
      "Epoch:10\n",
      "Epoch:11\n",
      "Epoch:12\n",
      "Epoch:13\n",
      "Epoch:14\n",
      "Epoch:15\n",
      "Epoch:16\n",
      "Epoch:17\n",
      "Epoch:18\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected parameter loc (Tensor of shape (512, 2)) of distribution MultivariateNormal(loc: torch.Size([512, 2]), covariance_matrix: torch.Size([512, 2, 2])) to satisfy the constraint IndependentConstraint(Real(), 1), but found invalid values:\ntensor([[nan, nan],\n        [nan, nan],\n        [nan, nan],\n        ...,\n        [nan, nan],\n        [nan, nan],\n        [nan, nan]], device='cuda:0', dtype=torch.float64,\n       grad_fn=<ExpandBackward0>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m Model \u001b[39m=\u001b[39m NN_Solver(config)\u001b[39m.\u001b[39mto(config\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m      2\u001b[0m problem \u001b[39m=\u001b[39m ContextProblem()\n\u001b[0;32m----> 4\u001b[0m train(Model, config,problem,run_id \u001b[39m=\u001b[39;49m run_id)\n",
      "File \u001b[0;32m~/Documents/PhD/TVAE-Opt/trainy_context.py:35\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, config, problem, run_id)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEpoch:\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(epoch_idx))\n\u001b[1;32m     34\u001b[0m \u001b[39m#Training\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m model,_,tracking_losses \u001b[39m=\u001b[39m train_epoch(\n\u001b[1;32m     36\u001b[0m     \n\u001b[1;32m     37\u001b[0m     model,\n\u001b[1;32m     38\u001b[0m     config,\n\u001b[1;32m     39\u001b[0m     epoch_idx,\n\u001b[1;32m     40\u001b[0m     optimizer,\n\u001b[1;32m     41\u001b[0m     optimizer_imp,\n\u001b[1;32m     42\u001b[0m     problem,\n\u001b[1;32m     43\u001b[0m \n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     46\u001b[0m \u001b[39m#Validation\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[39m#Not implemented yet\u001b[39;00m\n\u001b[1;32m     48\u001b[0m mean_optimality_gap \u001b[39m=\u001b[39m evaluate_epoch(model,config,problem)\n",
      "File \u001b[0;32m~/Documents/PhD/TVAE-Opt/trainy_context.py:144\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, config, epoch_idx, optimizer, optimizer_imp, problem)\u001b[0m\n\u001b[1;32m    141\u001b[0m batch_contexts \u001b[39m=\u001b[39m contexts[i\u001b[39m*\u001b[39mconfig\u001b[39m.\u001b[39mbatch_size:(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39mconfig\u001b[39m.\u001b[39mbatch_size]\n\u001b[1;32m    143\u001b[0m \u001b[39m#Encoder Decoder of Generated solutions\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m _,_,solution_logp,_,mu, log_var,_,_,_,_,_ \u001b[39m=\u001b[39m model(\n\u001b[1;32m    145\u001b[0m     \n\u001b[1;32m    146\u001b[0m     context \u001b[39m=\u001b[39;49m batch_contexts,\n\u001b[1;32m    147\u001b[0m     solution \u001b[39m=\u001b[39;49m batch_solutions,\n\u001b[1;32m    148\u001b[0m     config \u001b[39m=\u001b[39;49m config,\n\u001b[1;32m    149\u001b[0m     teacher_forcing \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    150\u001b[0m     greedy \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    151\u001b[0m \n\u001b[1;32m    152\u001b[0m )\n\u001b[1;32m    154\u001b[0m \u001b[39m#Create a Guassian Variable\u001b[39;00m\n\u001b[1;32m    155\u001b[0m latent_gaussian \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mgenerate_gaussian_vectors(config\u001b[39m.\u001b[39mbatch_size)\u001b[39m.\u001b[39mto(mu\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniconda3/envs/CVAE_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/PhD/TVAE-Opt/model.py:228\u001b[0m, in \u001b[0;36mNN_Solver.forward\u001b[0;34m(self, context, solution, config, teacher_forcing, greedy)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,context,solution,config,teacher_forcing \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,greedy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    226\u001b[0m \n\u001b[1;32m    227\u001b[0m     \u001b[39m#Encoding Solution\u001b[39;00m\n\u001b[0;32m--> 228\u001b[0m     Z, mu, log_var,Z_logp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    229\u001b[0m         \n\u001b[1;32m    230\u001b[0m         solution,\n\u001b[1;32m    231\u001b[0m         context,\n\u001b[1;32m    232\u001b[0m         \n\u001b[1;32m    233\u001b[0m     )\n\u001b[1;32m    237\u001b[0m     \u001b[39m#Decoding Solution\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     _, decoded_solution, tour_logp,_,_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(\n\u001b[1;32m    239\u001b[0m         \n\u001b[1;32m    240\u001b[0m         context \u001b[39m=\u001b[39m context,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    245\u001b[0m \n\u001b[1;32m    246\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/CVAE_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/PhD/TVAE-Opt/model.py:57\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, solution, context)\u001b[0m\n\u001b[1;32m     54\u001b[0m Z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreparameterise(mu, log_sigma)\n\u001b[1;32m     56\u001b[0m cov_mat \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdiag_embed(torch\u001b[39m.\u001b[39mexp(log_sigma))\u001b[39m.\u001b[39mto(mu\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m---> 57\u001b[0m m \u001b[39m=\u001b[39m MultivariateNormal(mu\u001b[39m.\u001b[39;49mdouble(), cov_mat\u001b[39m.\u001b[39;49mdouble())\n\u001b[1;32m     59\u001b[0m Z_logp \u001b[39m=\u001b[39m m\u001b[39m.\u001b[39mlog_prob(Z\u001b[39m.\u001b[39mdouble())\n\u001b[1;32m     61\u001b[0m \u001b[39mreturn\u001b[39;00m Z, mu, log_sigma, Z_logp\n",
      "File \u001b[0;32m~/miniconda3/envs/CVAE_env/lib/python3.9/site-packages/torch/distributions/multivariate_normal.py:146\u001b[0m, in \u001b[0;36mMultivariateNormal.__init__\u001b[0;34m(self, loc, covariance_matrix, precision_matrix, scale_tril, validate_args)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc \u001b[39m=\u001b[39m loc\u001b[39m.\u001b[39mexpand(batch_shape \u001b[39m+\u001b[39m (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,))\n\u001b[1;32m    145\u001b[0m event_shape \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:]\n\u001b[0;32m--> 146\u001b[0m \u001b[39msuper\u001b[39;49m(MultivariateNormal, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(batch_shape, event_shape, validate_args\u001b[39m=\u001b[39;49mvalidate_args)\n\u001b[1;32m    148\u001b[0m \u001b[39mif\u001b[39;00m scale_tril \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unbroadcasted_scale_tril \u001b[39m=\u001b[39m scale_tril\n",
      "File \u001b[0;32m~/miniconda3/envs/CVAE_env/lib/python3.9/site-packages/torch/distributions/distribution.py:55\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     53\u001b[0m         valid \u001b[39m=\u001b[39m constraint\u001b[39m.\u001b[39mcheck(value)\n\u001b[1;32m     54\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m valid\u001b[39m.\u001b[39mall():\n\u001b[0;32m---> 55\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     56\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected parameter \u001b[39m\u001b[39m{\u001b[39;00mparam\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(value)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m of shape \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(value\u001b[39m.\u001b[39mshape)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mof distribution \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mto satisfy the constraint \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(constraint)\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     60\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut found invalid values:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m \u001b[39msuper\u001b[39m(Distribution, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "\u001b[0;31mValueError\u001b[0m: Expected parameter loc (Tensor of shape (512, 2)) of distribution MultivariateNormal(loc: torch.Size([512, 2]), covariance_matrix: torch.Size([512, 2, 2])) to satisfy the constraint IndependentConstraint(Real(), 1), but found invalid values:\ntensor([[nan, nan],\n        [nan, nan],\n        [nan, nan],\n        ...,\n        [nan, nan],\n        [nan, nan],\n        [nan, nan]], device='cuda:0', dtype=torch.float64,\n       grad_fn=<ExpandBackward0>)"
     ]
    }
   ],
   "source": [
    "\n",
    "Model = NN_Solver(config).to(config.device)\n",
    "problem = Problem()\n",
    "\n",
    "train(Model, config,problem,run_id = run_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CVAE_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27e02dc85369733a903742787515facd417f96dea0ebccbb0c1c94899258b880"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
